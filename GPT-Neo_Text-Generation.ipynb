{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322dcba3-1eee-4c30-ba38-e8ae172d7f42",
   "metadata": {},
   "source": [
    "# GPT-Neo_Text-Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fc19f-9de8-4fe5-9e9d-8cba0238645f",
   "metadata": {},
   "source": [
    "https://huggingface.co/EleutherAI/gpt-neo-2.7B\n",
    "\n",
    "https://github.com/theonejohann/GPT-Neo_Text-Generation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6bf28c-bf54-403f-a31b-7b0fd5da8d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\one\\anaconda3\\lib\\site-packages (4.21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\one\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\one\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\one\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\one\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\one\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\one\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\one\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\one\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "print(\"Tensorflow Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Torch GPU is available:\", torch.cuda.is_available())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9603e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('input.txt', 'r')\n",
    "prompt = file.readlines()\n",
    "prompt = \"\".join(sentence)\n",
    "print(\"*Prompt is:* \\n\", prompt)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa83c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"EleutherAI has\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa15aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acee52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e0337744b078f5c5f12577a38f0745cc29a92c21b664e10c1601904ecdca383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
